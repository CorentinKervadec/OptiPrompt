{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How prompts influence LMs?\n",
    "\n",
    "Code for analyzing and comparing LM behavior given prompts of different nature (LAMA, Autoprompt, LPAQA)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CommitOperationAdd' from 'huggingface_hub' (/Users/corentk/miniconda3/envs/optiprompt/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m build_model_by_name\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_vocab, load_data, batchify, evaluate, get_relation_meta\n",
      "File \u001b[0;32m~/ALiEN/Prompting_prompts/source_code/OptiPrompt/code/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmaskedlm_connector\u001b[39;00m \u001b[39mimport\u001b[39;00m MaskedLM\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcausallm_connector\u001b[39;00m \u001b[39mimport\u001b[39;00m CausalLM\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_connector\u001b[39;00m \u001b[39mimport\u001b[39;00m LM_TYPE\n",
      "File \u001b[0;32m~/ALiEN/Prompting_prompts/source_code/OptiPrompt/code/models/maskedlm_connector.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_connector\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForMaskedLM, AutoModelForSeq2SeqLM, AutoConfig\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMaskedLM\u001b[39;00m(Base_Connector):\n\u001b[1;32m     11\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, args):\n",
      "File \u001b[0;32m~/miniconda3/envs/optiprompt/lib/python3.10/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logging,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/optiprompt/lib/python3.10/site-packages/transformers/dependency_versions_check.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     20\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/miniconda3/envs/optiprompt/lib/python3.10/site-packages/transformers/utils/__init__.py:58\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     28\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     ContextManagers,\n\u001b[1;32m     36\u001b[0m     ExplicitEnum,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     60\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m     61\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m     62\u001b[0m     HUGGINGFACE_CO_PREFIX,\n\u001b[1;32m     63\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     64\u001b[0m     PYTORCH_PRETRAINED_BERT_CACHE,\n\u001b[1;32m     65\u001b[0m     PYTORCH_TRANSFORMERS_CACHE,\n\u001b[1;32m     66\u001b[0m     S3_BUCKET_PREFIX,\n\u001b[1;32m     67\u001b[0m     TRANSFORMERS_CACHE,\n\u001b[1;32m     68\u001b[0m     TRANSFORMERS_DYNAMIC_MODULE_NAME,\n\u001b[1;32m     69\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     70\u001b[0m     PushToHubMixin,\n\u001b[1;32m     71\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m     72\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m     73\u001b[0m     cached_file,\n\u001b[1;32m     74\u001b[0m     default_cache_path,\n\u001b[1;32m     75\u001b[0m     define_sagemaker_information,\n\u001b[1;32m     76\u001b[0m     download_url,\n\u001b[1;32m     77\u001b[0m     extract_commit_hash,\n\u001b[1;32m     78\u001b[0m     get_cached_models,\n\u001b[1;32m     79\u001b[0m     get_file_from_repo,\n\u001b[1;32m     80\u001b[0m     get_full_repo_name,\n\u001b[1;32m     81\u001b[0m     has_file,\n\u001b[1;32m     82\u001b[0m     http_user_agent,\n\u001b[1;32m     83\u001b[0m     is_offline_mode,\n\u001b[1;32m     84\u001b[0m     is_remote_url,\n\u001b[1;32m     85\u001b[0m     move_cache,\n\u001b[1;32m     86\u001b[0m     send_example_telemetry,\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     90\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m     torch_version,\n\u001b[1;32m    164\u001b[0m )\n\u001b[1;32m    167\u001b[0m WEIGHTS_NAME \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpytorch_model.bin\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/optiprompt/lib/python3.10/site-packages/transformers/utils/hub.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     CommitOperationAdd,\n\u001b[1;32m     34\u001b[0m     HfFolder,\n\u001b[1;32m     35\u001b[0m     create_commit,\n\u001b[1;32m     36\u001b[0m     create_repo,\n\u001b[1;32m     37\u001b[0m     get_hf_file_metadata,\n\u001b[1;32m     38\u001b[0m     hf_hub_download,\n\u001b[1;32m     39\u001b[0m     hf_hub_url,\n\u001b[1;32m     40\u001b[0m     whoami,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile_download\u001b[39;00m \u001b[39mimport\u001b[39;00m REGEX_COMMIT_HASH, http_get\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     44\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     45\u001b[0m     LocalEntryNotFoundError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     hf_raise_for_status,\n\u001b[1;32m     49\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CommitOperationAdd' from 'huggingface_hub' (/Users/corentk/miniconda3/envs/optiprompt/lib/python3.10/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from models import build_model_by_name\n",
    "from utils import load_vocab, load_data, batchify, evaluate, get_relation_meta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize the logger, used to store info related to the experiment.\n",
    "Also, define the init_template function (idk what's the purpose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def init_template(prompt_file, relation):\n",
    "    relation = get_relation_meta(prompt_file, relation)\n",
    "    return relation['template']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle input argument, in this notebook we are only using the default arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', type=str, default='bert-base-cased', help='the huggingface model name')\n",
    "parser.add_argument('--output_dir', type=str, default='output', help='the output directory to store prediction results')\n",
    "parser.add_argument('--common_vocab_filename', type=str, default='common_vocab_cased.txt', help='common vocabulary of models (used to filter triples)')\n",
    "parser.add_argument('--prompt_file', type=str, default='prompts/LAMA_relations.jsonl', help='prompt file containing 41 relations')\n",
    "\n",
    "parser.add_argument('--test_data_dir', type=str, default=\"data/filtered_LAMA\")\n",
    "parser.add_argument('--eval_batch_size', type=int, default=32)\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=6)\n",
    "parser.add_argument('--output_predictions', default=True, help='whether to output top-k predictions')\n",
    "parser.add_argument('--k', type=int, default=5, help='how many predictions will be outputted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "The following lines of code are used to initialize an LM.\n",
    "Then the LM iterates on the evaluation data, using a specific prompt types (given as argument, see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Logger\n",
    "    logger.info(args)\n",
    "\n",
    "    # Initialize GPUs\n",
    "    device=torch.device(\"mps\") # if using Macbook M1 chip\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    logger.info('# GPUs: %d'%n_gpu)\n",
    "    if n_gpu == 0:\n",
    "        logger.warning('No GPU found! exit!')\n",
    "    logger.info('Model: %s'%args.model_name)\n",
    "\n",
    "    # Random seed\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    # Initialize the LM\n",
    "    model = build_model_by_name(args)\n",
    "\n",
    "    # Do something with the vocabulary, idk what\n",
    "    if args.common_vocab_filename is not None:\n",
    "        vocab_subset = load_vocab(args.common_vocab_filename)\n",
    "        logger.info('Common vocab: %s, size: %d'%(args.common_vocab_filename, len(vocab_subset)))\n",
    "        filter_indices, index_list = model.init_indices_for_filter_logprobs(vocab_subset)\n",
    "    else:\n",
    "        filter_indices = None\n",
    "        index_list = None\n",
    "\n",
    "    for relation in os.listdir(args.test_data_dir):\n",
    "        relation = relation.split(\".\")[0]\n",
    "        print(\"RELATION {}\".format(relation))\n",
    "\n",
    "        output_dir = os.path.join(args.output_dir, os.path.basename(args.prompt_file).split(\".\")[0],args.model_name.replace(\"/\",\"_\"))\n",
    "        os.makedirs(output_dir , exist_ok=True)\n",
    "\n",
    "        template = init_template(args.prompt_file, relation)\n",
    "        logger.info('Template: %s'%template)\n",
    "\n",
    "        test_data = os.path.join(args.test_data_dir, relation + \".jsonl\")\n",
    "        eval_samples = load_data(test_data, template, vocab_subset=vocab_subset, mask_token=model.MASK)\n",
    "        eval_samples_batches, eval_sentences_batches = batchify(eval_samples, args.eval_batch_size * n_gpu)\n",
    "        evaluate(model, eval_samples_batches, eval_sentences_batches, filter_indices, index_list, output_topk=output_dir if args.output_predictions else None)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiprompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "662d219937816f6a927dbe78c9454f7b90e5830c9b780179ed59961fb8578c42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
